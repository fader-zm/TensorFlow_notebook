## 3、Flume+kafka整合

**需求：**

利用flume监听网络端口的数据，通过kafka将flume传递的数据传入到broker中，利用kafka内置的consumer进行数据消费

### 3.1 配置flume

在flume的conf目录下编辑kafka.conf

```
a1.sources = r1
a1.sinks = k1
a1.channels = c1

# Describe/configure the source

a1.sources.r1.type = netcat
a1.sources.r1.bind = hadoop001
a1.sources.r1.port = 44444
a1.sources.r1.channels = c1

# Describe the sink

a1.sinks.k1.type = org.apache.flume.sink.kafka.KafkaSink
a1.sinks.k1.topic = topic1
a1.sinks.k1.brokerList = 127.0.0.1:9092
a1.sinks.k1.requiredAcks = 1
a1.sinks.k1.batchSize = 20
a1.sinks.k1.channel = c1

# Use a channel which buffers events in memory
a1.channels.c1.type = memory
a1.channels.c1.capacity = 1000
a1.channels.c1.transactionCapacity = 100
```

### 3.2 启动kafka

- 启动zookeeper

​	`bin/zkServer.sh start`

- 启动kafka

​	`bin/kafka-server-start.sh -daemon config/server.properties &`

- 新增topic

​	`bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic topic1`

- 启动Flume

  `bin/flume-ng agent --conf-file  conf/kafka.conf--name a1 -Dflume.root.logger=DEBUG,console`

- 利用telnet向指定端口发送数据

  `telnet localhost 44444`

- 启动consumer查看输出

  `bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --from-beginning --topic topic1`

### 3.3 总结

- 一个Topic可认为是一类消息，每个topic将被分成多个partition(区)
- 每个partition在存储层面是append log文件。任何发布到此partition的消息都会被直接追加到log文件的尾部
- 每条消息在文件中的位置称为offset（偏移量），offset为一个long型数字，它是唯一标记一条消息。kafka并没有提供其他额外的索引机制来存储offset，因为在kafka中几乎不允许对消息进行“随机读写”。

- kafka和JMS（Java Message Service）实现(activeMQ)不同的是:即使消息被消费,消息仍然不会被立即删除.
  - 日志文件将会根据broker中的配置要求,保留一定的时间之后删除;超时后文件会被清除,无论其中的消息是否被消费
  - kafka通过这种简单的手段,来释放磁盘空间,以及减少消息消费之后对文件内容改动的磁盘IO开支.

- 对于consumer而言,它需要保存消费消息的offset,对于offset的保存和使用,由consumer来控制;当consumer正常消费消息时,offset将会"线性"的向前驱动,即消息将依次顺序被消费.事实上consumer可以使用任意顺序消费消息,它只需要将offset重置为任意值..(offset将会保存在zookeeper中)

- kafka集群几乎不需要维护任何consumer和producer状态信息,这些信息有zookeeper保存;因此producer和consumer的客户端实现非常轻量级,它们可以随意离开,而不会对集群造成额外的影响.

- partitions的设计目的有多个
  - 最根本原因是kafka基于文件存储.通过分区,可以将日志内容分散到多个server上,来避免文件尺寸达到单机磁盘的上限,每个partiton都会被当前server(kafka实例)保存
  - 可以将一个topic切分多任意多个partitions,来提高保存/消费的效率.此外越多的partitions意味着可以容纳更多的consumer,有效提升并发消费的能力.
- **Kafka中ZooKeeper的用途**：正如ZooKeeper用于分布式系统的协调和促进，Kafka使用ZooKeeper也是基于相同的原因。ZooKeeper用于管理、协调Kafka代理。每个Kafka代理都通过ZooKeeper协调其它Kafka代理。当Kafka系统中新增了代理或者某个代理故障失效时，ZooKeeper服务将通知生产者和消费者。生产者和消费者据此开始与其它代理协调工作。Kafka整体系统架构所示。
- 一台服务器作为Leader，其它作为Follower。当Ensemble启动时，先选出Leader，然后所有Follower复制Leader的状态。所有写请求都通过Leader路由，变更会广播给所有Follower。变更广播被称为原子广播。